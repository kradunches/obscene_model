# obscene_model
In this project a model trained on a dataset with obscene language determines whether the text entered by the user in html form is offensive or not.

Data for model was taken from Kaggle repository:
https://www.kaggle.com/competitions/jigsaw-multilingual-toxic-comment-classification/overview

# Files
+ jigsaw-toxic-comment-train.csv - the data on which the model was trained, more detailed information can be found in the kaggle repository, the link to which was above
